{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+iUja7WV/BisHgv/2dqyf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dev-chaitanya-dewangan/CHATGPT_TRANSFORM_FROM_SCRATCH/blob/main/LLM_FROM_SCRATCH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PREP"
      ],
      "metadata": {
        "id": "TRzYCvG0OJZt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0ehBrOX-MEha"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "url = \"https://www.gutenberg.org/cache/epub/76137/pg76137.txt\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Get the text content\n",
        "full_text = response.text\n",
        "first_index = full_text.find(\"PREFACE\")\n",
        "second_index = full_text.find(\"PREFACE\", first_index + 1)\n",
        "# Preview first 500 characters\n",
        "book= full_text[second_index:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preproccesed_cleaned_text = re.split(r'([,.:;?_!\"()\\']|--|\\s)',book)\n",
        "preporcessed_result=[item.strip() for item in preproccesed_cleaned_text if item.strip()]"
      ],
      "metadata": {
        "id": "LW2SFb8qiN9p"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXTENED WITH UNK AND ENDOF TEXT**"
      ],
      "metadata": {
        "id": "4ld_NlhPiPKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preporcessed_sorted_result=sorted(set(preporcessed_result))\n",
        "preporcessed_sorted_result.extend([\"<|endoftext|>\",\"<|unk|>\"])"
      ],
      "metadata": {
        "id": "gUkOSLJjiON5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vocab={token:id for id,token in enumerate(preporcessed_sorted_result)}\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JLNH4wQQO7-W"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOKENIZER\n"
      ],
      "metadata": {
        "id": "jmKNB_m0YnAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "  def __init__(self,vocab):\n",
        "    self.encoded_vocab=vocab\n",
        "    self.decoded_vocab={id:word for word,id in vocab.items()}\n",
        "\n",
        "  def encode(self,text):\n",
        "    text_cleaning=re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
        "    preporccesed_text=[item.strip() for item in text_cleaning if item.strip()]\n",
        "    tokenized_text = [self.encoded_vocab[i] for i in preporccesed_text]\n",
        "    return tokenized_text\n",
        "  def decode(self,tokens):\n",
        "    text=\" \".join([self.decoded_vocab[i] for i in tokens])\n",
        "    text=re.sub('\\s+([,.?!\"()\\'])',r'\\1',text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "kgs5MmMwO_Jc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEW TOKENIZER EXTENDED WITH THE UNKOWN TEXT AND END OF TEXT\\"
      ],
      "metadata": {
        "id": "dyi2_RrFjlRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TokenizerV2:\n",
        "  def __init__(self,vocab):\n",
        "    self.encoded_vocab=vocab\n",
        "    self.decoded_vocab={id:word for word,id in vocab.items()}\n",
        "\n",
        "  def encode(self,text):\n",
        "    text_cleaning=re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
        "    preporccesed_text=[item.strip() for item in text_cleaning if item.strip()]\n",
        "    # tokenized_text = [self.encoded_vocab[i] for i in preporccesed_text] CHANGED HERE\n",
        "    tokenized_text = [i if i in self.encoded_vocab else \"<|unk|>\" for i in preporccesed_text]\n",
        "    return tokenized_text\n",
        "  def decode(self,tokens):\n",
        "    text=\" \".join([self.decoded_vocab[i] for i in tokens])\n",
        "    text=re.sub('\\s+([,.?!\"()\\'])',r'\\1',text)\n",
        "    return text\n",
        ""
      ],
      "metadata": {
        "id": "bLNvdygVO_MS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=TokenizerV2(vocab)\n"
      ],
      "metadata": {
        "id": "r5_E2-50v4co"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "class GPTEncoder(Dataset):\n",
        "  def __init__(self,txt,tokenizer,max_length,stride):\n",
        "    self.input=[]\n",
        "    self.target=[]\n",
        "    tokenized_text=tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
        "    for i in range(0,len(tokenized_text)-max_length,stride):\n",
        "      input=tokenized_text[i:i+max_length]\n",
        "      target=tokenized_text[i+1:1+i+max_length]\n",
        "      self.input.append(torch.tensor(input))\n",
        "      self.target.append(torch.tensor(target))\n",
        "  def __len__(self):\n",
        "    return len(self.input)\n",
        "  def __getitem__(self,pos):\n",
        "    return self.input[pos],self.target[pos]\n",
        "\n",
        "def create_dataloader(txt,batch_size=4,max_length=256\n",
        "                      ,stride=128,shuffle=True\n",
        "                      ,drop_last=True,num_workers=0):\n",
        "  tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTEncoder(txt,tokenizer,max_length,stride)\n",
        "  dataloader=DataLoader(\n",
        "      dataset=dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      drop_last=drop_last,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "  return dataloader\n",
        "book= full_text[second_index:]\n",
        "batch_dataloader=create_dataloader(book,batch_size=1,max_length=12,stride=120,shuffle=False)\n",
        "data_iter=iter(batch_dataloader)\n",
        "# first=next(batch_dataloader)\n",
        "print(next(data_iter))"
      ],
      "metadata": {
        "id": "uZxmxh_tO_Oq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea845da-9bd2-4e07-d397-620edfd5f20a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[   47, 31688, 11598,    13,   201,   198,   201,   198,   201,   198,\n",
            "           464,  1204]]), tensor([[31688, 11598,    13,   201,   198,   201,   198,   201,   198,   464,\n",
            "          1204,   286]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SIMPLIFIED SELF ATTENTION**"
      ],
      "metadata": {
        "id": "mQNgJ7O4wmHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")\n",
        "\n",
        "attenS=torch.empty(inputs.shape[0])\n",
        "query = inputs[1]\n",
        "for i,x_i in  enumerate(inputs):\n",
        "  attenS[i]=torch.dot(x_i,query)\n",
        "\n",
        "print(attenS)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "966PA7Fauzfc",
        "outputId": "fcabe639-8358-4626-871f-408b6a1ee352"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attenS=torch.softmax(attenS,dim=0)\n",
        "print(attenS.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlz9V8uPwdHe",
        "outputId": "db83203c-e7e0-4e4b-ea87-f3f3c5deb82e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(\n",
        "  [[3,5,9], # Your     (x^1)\n",
        "   [5,7,6], # journey  (x^2)\n",
        "   [7,5,4], # starts   (x^3)\n",
        "   [2,8,3], # with     (x^4)\n",
        "   [7,5,0], # one      (x^5)\n",
        "   [5,0,5]] # step     (x^6)\n",
        ",dtype=torch.float32)\n",
        "\n",
        "atten_scores=inputs @ inputs.T\n",
        "attention_weights=torch.softmax(atten_scores,dim=-1)\n",
        "context=attention_weights @ atten_scores\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8CPLX5X6O_Re",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a80cfd-790b-497f-d765-ee666c3d8b51"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nvbb0TlOwhh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9SHhu8TAO_UK"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}